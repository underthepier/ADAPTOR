{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au23zBgFiEft"
      },
      "source": [
        "# IMPORT DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "GEfSoRy3iEfu"
      },
      "outputs": [],
      "source": [
        "#@title Input field test information and click the play button {display-mode: \"form\"}\n",
        "\n",
        "#A short nickname for the field test\n",
        "\n",
        "fieldTestLabel = \"AKA Ocean City\" #@param {type: \"string\"}\n",
        "\n",
        "#Name of the location of the field test\n",
        "fieldTestLocation = \"Princess Royale Oceanfront Resort\" #@param {type: \"string\"}\n",
        "\n",
        "#The date of the field test\n",
        "fieldTestDate = \"2022-10-11\" #@param {type: \"date\"}\n",
        "\n",
        "#A short description of the overall field test purpose\n",
        "fieldTestDescription = \"Flying two kestrels together\" #@param {type: \"string\"}\n",
        "\n",
        "#Initials for members of the field test\n",
        "fieldTestTeam = \"RAC, GB, DJ\" #@param {type: \"string\"}\n",
        "\n",
        "#Initials of person/people analyzing the data\n",
        "dataAnalyst = \"DJ\" #@param {type: \"string\"}\n",
        "\n",
        "#Name of the Kestrel Device\n",
        "deviceName = \"Drexel Kestrel 5500 A\" #@param {type: \"string\"}\n",
        "\n",
        "#Nickname to identify the device on the plots\n",
        "deviceNickName = \"Aeropod\" #@param {type: \"string\"}\n",
        "\n",
        "#Name of folder to store the trimmed data\n",
        "trimmedDataFolderName = \"trimmed_data\" #@param {type: \"string\"}\n",
        "\n",
        "#Name of folder to store the preprocessed data\n",
        "preprocessedDataFolderName = \"preprocessed_data\" #@param {type: \"string\"}\n",
        "\n",
        "#Name of folder to store the generated plots\n",
        "plotsFolderName = \"plots\" #@param {type: \"string\"}\n",
        "\n",
        "###########################################################################################\n",
        "import time as tm\n",
        "from datetime import date\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#Information to indicate the history of changes made\n",
        "change_history = []\n",
        "\n",
        "#Convert fieldTestDate to a datetime object for easy manipulations\n",
        "try:\n",
        "    fieldTestDate = date.fromisoformat(fieldTestDate)\n",
        "    fieldTestDate = fieldTestDate.strftime(\"%A, %B %d, %Y\")\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "except Exception as e:\n",
        "    print(\"Something went wrong. Restart the notebook\")\n",
        "\n",
        "#Field test parameters into a dictionary\n",
        "fieldTestParameters = {\n",
        "    \"Field Test Label\": fieldTestLabel,\n",
        "    \"Field Test Location\": fieldTestLocation,\n",
        "    \"Field Test Date\": fieldTestDate,\n",
        "    \"Field Test Description\": fieldTestDescription,\n",
        "    \"Field Test Team\": fieldTestTeam,\n",
        "    \"Data Analyst\": dataAnalyst,\n",
        "    \"Device Name\": deviceName,\n",
        "    \"Device Nickname\": deviceNickName,\n",
        "}\n",
        "\n",
        "#Echo field test parameters for user to confirm and change if necessary\n",
        "print(\"PLEASE CONFIRM THE FOLLOWING FIELD TEST PARAMETERS\")\n",
        "print(\"-\"*50)\n",
        "\n",
        "for parameter in fieldTestParameters:\n",
        "    print(f\"{parameter}: {fieldTestParameters[parameter]}\")\n",
        "    change_history.append(f\"{parameter}: {fieldTestParameters[parameter]}\")\n",
        "    \n",
        "print(\"-\"*50)\n",
        "\n",
        "#Get the directory that the notebook is currently in\n",
        "cwd = os.getcwd()\n",
        "\n",
        "#Create trimmed data directory\n",
        "try:\n",
        "    trimmed_data_dir = Path(trimmedDataFolderName)\n",
        "    trimmed_data_dir.mkdir()\n",
        "    change_history.append(f\"{trimmedDataFolderName} folder was created in {cwd}\")\n",
        "except FileExistsError:\n",
        "    print(f\"The folder, {trimmedDataFolderName}, already exists\")\n",
        "except Exception as e:\n",
        "    print(\"Something went wrong. Restart the notebook\")\n",
        "else:\n",
        "    print(f\"{trimmedDataFolderName} has been created in {cwd}\")\n",
        "\n",
        "#Create preprocessed data directory\n",
        "try:\n",
        "    preprocessed_data_dir = Path(preprocessedDataFolderName)\n",
        "    preprocessed_data_dir.mkdir()\n",
        "    change_history.append(f\"{preprocessedDataFolderName} folder was created in {cwd}\")\n",
        "except FileExistsError:\n",
        "    print(f\"The folder, {preprocessedDataFolderName}, already exists\")\n",
        "except Exception as e:\n",
        "    print(\"Something went wrong. Restart the notebook\")\n",
        "else:\n",
        "    print(f\"{preprocessedDataFolderName} has been created in {cwd}\")\n",
        "\n",
        "#Create plots directory\n",
        "try:\n",
        "    plots_dir = Path(plotsFolderName)\n",
        "    plots_dir.mkdir()\n",
        "    change_history.append(f\"{plotsFolderName} folder was created in {cwd}\")\n",
        "except FileExistsError:\n",
        "    print(f\"The folder, {plotsFolderName}, already exists\")\n",
        "except Exception as e:\n",
        "    print(\"Something went wrong. Restart the notebook\")\n",
        "else:\n",
        "    print(f\"{plotsFolderName} has been created in {cwd}\")\n",
        "\n",
        "\n",
        "\n",
        "#Parameters to tell user to run certain cells before others\n",
        "generate_plots = False\n",
        "customize_plots = False\n",
        "time_series_superimposed_step = False\n",
        "customize_plots_message = \"Please FIRST run the Customize Plots cell before generating plots\"  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "id": "bKyJ1rI3Hujj"
      },
      "outputs": [],
      "source": [
        "#@title Click the play button to upload a file {display-mode: \"form\"}\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "filename = list(uploaded.keys())[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "1FVurO0giEfy"
      },
      "outputs": [],
      "source": [
        "#@title Click the play button to open the file {display-mode: \"form\"}\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout, Button, Box\n",
        "\n",
        "\n",
        "plot_units = {\n",
        "    \"Meters per second\": \"Wind Speed (m/s)\",\n",
        "    \"Feet per second\": \"Wind Speed (ft/s)\",\n",
        "    \"Miles per hour\": \"Wind Speed (mph)\",\n",
        "    \"Knots\": \"Wind Speed (kt)\",\n",
        "    \"Beaufort\": \"Wind Speed (Bft)\",\n",
        "    \"Meters\": \"AOG (Meters)\",\n",
        "    \"Feet\": \"AOG (Feet)\",\n",
        "    \"Celsius\": \"Temp (Celsius)\",\n",
        "    \"Fahrenheit\": \"Temp (Fahrenheit)\",\n",
        "}\n",
        "\n",
        "#Used to preselect the fields in the field selection widget\n",
        "standard_fields = {\n",
        "    \"Time\": \"Time (yyyy-MM-dd hh:mm:ss)\",\n",
        "    \"Altitude\": \"Altitude (Meters)\",\n",
        "    \"Wind Speed\": \"Wind Speed (m/s)\",\n",
        "    \"Mag. Dir.\": \"Mag. Dir. (Degrees)\",        \n",
        "    \"Temp\": \"Temp (Celsius)\",\n",
        "    \"Rel. Hum.\": \"Rel. Hum. (%)\",\n",
        "    #\"Baro.\": \"Baro. (mb)\",\n",
        "}\n",
        "\n",
        "glyphs = {\n",
        "    \"Altitude\": \"square\",\n",
        "    \"Temp\" : \"triangle\",\n",
        "    \"Wet Bulb Temp.\": \"hex\",\n",
        "    \"Wind Speed\": \"diamond_cross\",\n",
        "    \"Rel. Hum.\": \"circle\",\n",
        "    \"Mag. Dir.\": \"cross\",\n",
        "    \"Baro.\": \"star\",\n",
        "}\n",
        "\n",
        "#Check if there's anything wrong with the file in the first place\n",
        "try:\n",
        "    print(f\"Opening \\\"{filename}\\\"\", end=\"\")\n",
        "    \n",
        "    for i in range(2):\n",
        "        print(\".\", end=\"\")\n",
        "    print(\".\")\n",
        "    \n",
        "    f = open(filename, \"r\")\n",
        "    print(\"File opened successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Something went wrong\")\n",
        "    print(e)\n",
        "    \n",
        "else:\n",
        "    #READ PROLOGUE   \n",
        "    ####################################################################################\n",
        "\n",
        "    prologue_length = 8 #replace this comment with the length of your prologue (optional for user to interact or get rid of?)\n",
        "\n",
        "    ####################################################################################\n",
        "    try:\n",
        "        #Iterate over prologue\n",
        "        print(\"\\nReading prologue\")\n",
        "        #print(\"-\"*50)\n",
        "        pl = 0\n",
        "        prologue = []\n",
        "\n",
        "        while True:\n",
        "            l = f.readline()\n",
        "            prologue.append(l)\n",
        "            #print(l)\n",
        "            if l == \"\\n\":\n",
        "                break\n",
        "            else:\n",
        "                pl += 1\n",
        "        #print(\"-\"*50)        \n",
        "        print(\"Prologue read successfully\")\n",
        "\n",
        "        if pl != prologue_length:\n",
        "            print(f\"Prologue was {pl} lines instead of {prologue_length}\")\n",
        "        else:\n",
        "            print(f\"Prologue is {prologue_length} lines\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Something went wrong\")\n",
        "        print(e)\n",
        "\n",
        "    #READ HEADERS, UNITS, AND DATA\n",
        "    ####################################################################################\n",
        "\n",
        "    #Run this cell once\n",
        "\n",
        "    try:\n",
        "        #Obtaining headers and units\n",
        "        print(\"\\nObtaining headers\")\n",
        "        headers = f.readline().split(\",\")\n",
        "        headers.pop(-1)\n",
        "        print(\"Headers obtained successfully\")\n",
        "        print(\"\\nObtaining units\")\n",
        "  \n",
        "        units = f.readline().split(\",\")\n",
        "        units.pop(-1)\n",
        "        print(\"Units obtained successfully\")\n",
        "  \n",
        "\n",
        "        #Store the data values into a pandas dataframe\n",
        "        print(\"\\nObtaining measurements\")\n",
        "          \n",
        "        raw_df = pd.read_csv(f, names=headers)\n",
        "        f.close()        \n",
        "        \n",
        "        \"\"\"\n",
        "        #Keep the standardized columns\n",
        "        for i, n in zip(headers, units):\n",
        "            if i in kestrel_units:\n",
        "                if kestrel_units[i] == n:\n",
        "                    new_label = i + \" (\" + n + \")\"\n",
        "                    df.rename(columns = {i: new_label}, inplace = True)\n",
        "                else:\n",
        "                    #TODO\n",
        "                    print(f\"Need to convert {n} to {kestrel_units[i]}\")\n",
        "            else:\n",
        "                df.drop(columns=i, inplace=True)\n",
        "        \"\"\"\n",
        "        columns = {}\n",
        "        raw_units = {}\n",
        "        for i, n in zip(headers, units):\n",
        "            new_label = i + \" (\" + n + \")\"\n",
        "            raw_df.rename(columns = {i: new_label}, inplace = True)\n",
        "            columns[i] = new_label\n",
        "            raw_units[i] = n\n",
        "\n",
        "        df_rows = raw_df.shape[0]\n",
        "        print(\"Data obtained successfully\")\n",
        "  \n",
        "        print(f\"\\n{df_rows} rows in file\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Something went wrong\")\n",
        "        print(e)\n",
        "        \n",
        "    #Variables to prevent cells from accidentally being run again, and potentially messing up the workflow\n",
        "    timedeltas_read = False\n",
        "\n",
        "    display(raw_df)\n",
        "    \n",
        "    field_select = widgets.SelectMultiple(\n",
        "    options=headers[1:], #This indexing assumes that Time will always be in the first column\n",
        "    value=[field for field in headers if (field in standard_fields and field != \"Time\")],\n",
        "    rows=len(headers),\n",
        "    #description='Select the fields to analyze',\n",
        "    disabled=False\n",
        "    )\n",
        "    print(f\"Ctrl+click (command+click for Mac) to select the fields to analyze\")\n",
        "    display(field_select)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYCvg5S9iEf0"
      },
      "outputs": [],
      "source": [
        "#@title Click the play button to confirm field selection {display-mode: \"form\"}\n",
        "\n",
        "#This method rearranges the standard columns in the standardized order (non-standard columns will stay in the same place)\n",
        "\n",
        "#First appends the standard columns in the standardized order\n",
        "fields = [field for field in standard_fields]\n",
        "fields_not_selected = [column for column in field_select.options if column not in field_select.value]\n",
        "\n",
        "#Appends the non-standard columns\n",
        "for field in field_select.value:\n",
        "    if field != \"Time\" and field not in fields:\n",
        "        fields.append(field)\n",
        "\n",
        "#Remove the standard columns if it wasn't selected\n",
        "for field in fields:\n",
        "    if field in fields_not_selected:\n",
        "        fields.remove(field)\n",
        "\n",
        "selected_units = {key: raw_units[key] for key in fields} \n",
        "        \n",
        "fields = [columns[field] for field in fields]\n",
        "df = raw_df[fields]\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "#Automatic error checking######################################################\n",
        "\n",
        "#LOOK FOR ANY CORRUPT FIELDS, NAN, ETC\n",
        "#ERROR CHECKING ON UNITS \n",
        "indices = []\n",
        "invalidcols = []\n",
        "nullcols = []\n",
        "\n",
        "asterisks_bool = False\n",
        "nulls_bool = False\n",
        "\n",
        "#Find columns with *** entries\n",
        "asterisks = df.isin([\"***\"])\n",
        "for col in asterisks.columns:\n",
        "    if asterisks[col].values.any():\n",
        "        invalidcols.append(col)\n",
        "\n",
        "if len(invalidcols) != 0:\n",
        "    asterisks_bool = True\n",
        "    \n",
        "#Find columns with NaN values\n",
        "nulls = df.isnull()\n",
        "for col in nulls.columns:\n",
        "    if nulls[col].values.any():\n",
        "        nullcols.append(col)\n",
        "\n",
        "if len(nullcols) != 0:\n",
        "    nulls_bool = True\n",
        "\n",
        "#Find the specific rows in the entire dataframe\n",
        "if asterisks_bool and nulls_bool:\n",
        "    for i in range(len(df)):\n",
        "        invalid = df.iloc[i]\n",
        "        if invalid.hasnans: \n",
        "            indices.append(i)\n",
        "        if (\"***\" in invalid.values): #reference https://stackoverflow.com/questions/30944577/check-if-string-is-in-a-pandas-dataframe\n",
        "            indices.append(i)\n",
        "elif asterisks_bool:\n",
        "    for i in range(len(df)):\n",
        "        invalid = df.iloc[i]\n",
        "        if (\"***\" in invalid.values): #reference https://stackoverflow.com/questions/30944577/check-if-string-is-in-a-pandas-dataframe\n",
        "            indices.append(i)\n",
        "elif nulls_bool:\n",
        "    for i in range(len(df)):\n",
        "        invalid = df.iloc[i]\n",
        "        if invalid.hasnans: \n",
        "            indices.append(i)\n",
        "\n",
        "indices = set(indices) #Use a set to ignore duplicates\n",
        "\n",
        "if len(indices) == 0:\n",
        "    print(\"No errors have been detected\")\n",
        "    print(\"Proceed to TRIM DATA step\")\n",
        "\n",
        "if asterisks_bool and nulls_bool:\n",
        "    print(\"*** entries have been detected in the following columns\")\n",
        "    print(*invalidcols, sep=\"\\n\")\n",
        "    print(\"NaN entries have been detected in the following columns\")\n",
        "    print(*nullcols, sep = \"\\n\")\n",
        "\n",
        "elif asterisks_bool:\n",
        "    print(\"*** entries have been detected in the following columns\")\n",
        "    print(*invalidcols, sep=\"\\n\")\n",
        "    \n",
        "elif nulls_bool:\n",
        "    print(\"NaN entries have been detected in the following columns\")\n",
        "    print(*nullcols, sep = \"\\n\")\n",
        "    \n",
        "#check nulls reference https://www.geeksforgeeks.org/check-for-nan-in-pandas-dataframe/\n",
        "\n",
        "if asterisks_bool or nulls_bool:\n",
        "\n",
        "  #Replace the *** entries with a value\n",
        "  error_value = 500 #Arbitrary number chosen after HTTP 500 Error code\n",
        "\n",
        "  ##################################################################################\n",
        "\n",
        "  asterisks = df != \"***\"\n",
        "  df = df.where(asterisks, error_value)\n",
        "  for col in invalidcols:\n",
        "      change_history.append(f\"\\nAll *** values in the {col} column were replaced with a {error_value}\\n\")\n",
        "      print(change_history[-1])\n",
        "\n",
        "\n",
        "  #Convert header data types to expected data types\n",
        "  df[df.columns[0]] = pd.to_datetime(df[df.columns[0]])\n",
        "  change_history.append(f\"The {df.columns[0]} column was converted to type datetime\\n\")\n",
        "  print(f\"The {df.columns[0]} column was converted to type datetime\\n\")\n",
        "\n",
        "  expected_dtypes = {\n",
        "      \"Crosswind (m/s)\": \"float\",\n",
        "      \"Headwind (m/s)\": \"float\",\n",
        "      \"Mag. Dir. (Degrees)\": \"int\",\n",
        "      \"True Dir. (Degrees)\": \"int\"\n",
        "  }\n",
        "\n",
        "  for col in expected_dtypes:\n",
        "      if col in df:\n",
        "          df[col] = df[col].astype(expected_dtypes[col])\n",
        "          change_history.append(f\"The {col} column was converted to type {expected_dtypes[col]}\\n\")\n",
        "          print(change_history[-1])\n",
        "\n",
        "  ch_bound_1 = len(change_history)\n",
        "\n",
        "  print(\"Data types have been successfully changed\")\n",
        "  print(\"\\n\")\n",
        "  print(\"Proceed to TRIM DATA step\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ6JvcHKiEf0"
      },
      "source": [
        "***END OF IMPORT DATA STAGE***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1oZeUJhiEf3"
      },
      "source": [
        "# TRIM DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use interactive plots to help identify where to trim\n",
        "\n",
        "1. Execute the cell below\n",
        "2. The generated charts are intended to help identify the indices corresponding to your field test/data of interest\n",
        "    - Example: a field test on October 11, 2022 from 4PM to 5PM correspond to indices 529-1370\n",
        "3. Use the first index as `start_index` and the last index as `end_index`\n",
        "    - Example: \n",
        "    `start_index` = 529, `end_index` = 1370"
      ],
      "metadata": {
        "id": "v72nq3F2nTef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "9nVc_J8miEf4"
      },
      "outputs": [],
      "source": [
        "#@title Click the play button to use interactive plots to identify field test {display-mode: \"form\"}\n",
        "#Calculating Time Deltas###########################################################\n",
        "if not timedeltas_read:\n",
        "    #Date column as string variable\n",
        "    date = columns[\"Time\"]\n",
        "    \n",
        "    try:\n",
        "        #Also here if the error checking steps were skipped\n",
        "        if df[date].dtype != \"<M8[ns]\":\n",
        "            df.loc[:,date] = pd.to_datetime(df.loc[:,date])         \n",
        "            change_history.append(f\"The \\\"{date}\\\" column was converted to type datetime\\n\")\n",
        "            print(f\"The \\\"{date}\\\" column was converted to type datetime\\n\")\n",
        "\n",
        "        #List to store deltas\n",
        "        deltas = []\n",
        "\n",
        "        #Total number of data entry rows\n",
        "        rows = len(df)\n",
        "\n",
        "        #Calculate all time deltas and store in list\n",
        "        i = 0\n",
        "        while i != (rows-1):\n",
        "            time1 = df.loc[i,date]\n",
        "            time2 = df.loc[i+1,date]\n",
        "            delta = time2 - time1\n",
        "            deltas.append(delta)\n",
        "            i+=1\n",
        "        td_min = min(deltas)\n",
        "        td_max = max(deltas)\n",
        "        deltas.append(\"LAST TIME ENTRY\") #Helper text\n",
        "\n",
        "        #Convert list to series\n",
        "        deltas = pd.Series(deltas, name=\"Time Delta\")\n",
        "\n",
        "        #Store the sampling interval of 2s, or whatever sampling interval was chosen (which should be the most common)        \n",
        "        mode = deltas.mode()\n",
        "\n",
        "        #Create separate series of time deltas in seconds\n",
        "        td_seconds = []\n",
        "        for td in deltas:\n",
        "            if isinstance(td, str): #Necessary for entries with helper text\n",
        "                td_seconds.append(td)\n",
        "            else:\n",
        "                td_seconds.append(td.total_seconds())\n",
        "        td_seconds = pd.Series(td_seconds, name=\"Time Delta (seconds)\")\n",
        "\n",
        "        #Initialize dataframe with datetime columns\n",
        "        times = pd.DataFrame(df[date]).rename(columns={date:\"Datetime\"})\n",
        "\n",
        "        #Create datetime + 1 and datetime - 1 series to be added into times df\n",
        "        dtplusone = pd.Series(index=range(rows), name=\"Datetime_i+1\", dtype=\"object\")\n",
        "        dtminusone = pd.Series(index=range(rows), name=\"Datetime_i-1\", dtype=\"object\")\n",
        "\n",
        "        #Append necessary values\n",
        "        dtplusone[0:-1] = df.loc[1:, date]\n",
        "        dtplusone[rows-1] = \"LAST TIMESTAMP\" #Helper text---is it necessary?\n",
        "\n",
        "        dtminusone[1:] = df.loc[:rows-2, date]\n",
        "        dtminusone[0] = \"FIRST TIMESTAMP\" #Helper text---is it necessary?\n",
        "\n",
        "        times = times.join([deltas, td_seconds, dtminusone, dtplusone])\n",
        "\n",
        "        #Reorder columns to desired order\n",
        "        times = times[[\"Datetime\", \"Datetime_i+1\", \"Time Delta\", \"Time Delta (seconds)\", \"Datetime_i-1\"]]\n",
        "\n",
        "        #Reordering columns\n",
        "        df.insert(loc = 1,\n",
        "          column = 'Time Delta',\n",
        "          value = deltas,\n",
        "          allow_duplicates=True)\n",
        "        \n",
        "        df.insert(loc = 2,\n",
        "          column = 'Time Delta (seconds)',\n",
        "          value = td_seconds,\n",
        "          allow_duplicates=True)\n",
        "        \n",
        "        print(\"Code has calculated the time between data points as a new column labeled <Time Delta (seconds)>\")\n",
        "        print(f\"Most common sampling time in datafile is {mode[0].seconds} seconds\")\n",
        "        #display(df[df.columns[1:3]])\n",
        "  \n",
        "        timedeltas_read = True\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    ch_bound_1 = len(change_history)\n",
        "else:\n",
        "    print(\"Code has calculated the time between data points as a new column labeled <Time Delta (seconds)>\")\n",
        "    print(f\"Most common sampling time in datafile is {mode[0].seconds} seconds\")\n",
        "    #display(df[df.columns[1:3]])\n",
        "    ch_bound_1 = len(change_history)\n",
        "\n",
        "################################################################################\n",
        "\n",
        "\n",
        "\n",
        "#Calculating time delta outliers################################################\n",
        "outliers = []\n",
        "outliers_index = []\n",
        "\n",
        "#Find the time deltas != chosen sampling interval\n",
        "for count, i in enumerate(deltas):\n",
        "    if not (i==mode).any():\n",
        "        outliers.append(i)\n",
        "        outliers_index.append(count)\n",
        "outliers = pd.Series(outliers, name=\"Time Deltas != sampling interval\")\n",
        "\n",
        "#Time deltas in seconds\n",
        "outliers_seconds = []\n",
        "for td in outliers:\n",
        "    if isinstance(td, str): #Necessary for entries with helper text\n",
        "        outliers_seconds.append(td)\n",
        "    else:\n",
        "        outliers_seconds.append(td.total_seconds())\n",
        "outliers_seconds = pd.Series(outliers_seconds, name=\"Time Delta (seconds)\")\n",
        "\n",
        "print(\"Outliers in sampling time calculated\")\n",
        "\n",
        "#Initialize time delta != sampling interval comparison chart\n",
        "td = \"Time Delta\"\n",
        "tds = \"Time Delta (Seconds)\"\n",
        "dt = \"Datetime\"\n",
        "dtmin = \"Datetime_i-1\"\n",
        "dtplus = \"Datetime_i+1\"\n",
        "columnnames = [dt, dtplus, td, tds, dtmin] #REARRANGE COLUMNS HERE TO DESIRED LAYOUT\n",
        "\n",
        "td = columnnames.index(td)\n",
        "tds = columnnames.index(tds)\n",
        "dt = columnnames.index(dt)\n",
        "dtmin = columnnames.index(dtmin)\n",
        "dtplus = columnnames.index(dtplus)\n",
        "\n",
        "outliers_df = pd.DataFrame(index=outliers_index, columns=columnnames)\n",
        "\n",
        "#Append Time Deltas\n",
        "for index, value in enumerate(outliers):\n",
        "    outliers_df.iloc[index, td] = value\n",
        "\n",
        "for index, value in enumerate(outliers_seconds):\n",
        "    outliers_df.iloc[index, tds] = value\n",
        "\n",
        "#Append Datetimes\n",
        "for row, index in enumerate(outliers_index):\n",
        "    if index == 0:\n",
        "        outliers_df.iloc[row, dt] = df.loc[index, date] #Datetime\n",
        "        outliers_df.iloc[row, dtmin] = \"FIRST ENTRY\"#Datetime_i-1\n",
        "        outliers_df.iloc[row, dtplus] = df.loc[index+1, date]#Datetime_i+1\n",
        "    elif index == rows-1:\n",
        "        outliers_df.iloc[row, dt] = df.loc[index, date] #Datetime\n",
        "        outliers_df.iloc[row, dtmin] = df.loc[index-1, date]#Datetime_i-1\n",
        "        outliers_df.iloc[row, dtplus] = \"NO ENTRY\"#Datetime_i+1\n",
        "    else:\n",
        "        outliers_df.iloc[row, dt] = df.loc[index, date] #Datetime\n",
        "        outliers_df.iloc[row, dtmin] = df.loc[index-1, date]#Datetime_i-1\n",
        "        outliers_df.iloc[row, dtplus] = df.loc[index+1, date]#Datetime_i+1\n",
        "print(\"Sampline time chart successfully created\")\n",
        "print(f\"\\nMost common sampling time in datafile is {mode[0].seconds} seconds\")\n",
        "print()\n",
        "print(60*'*')\n",
        "print(\"The following table displays all sampling times that are NOT equal to the most common sampling time.\")\n",
        "print(\"These rows in the table may correspond to times when the device was turned off and then back on\")\n",
        "print(\"or other events that affect the recorded sample times\")\n",
        "print(60*'*')\n",
        "display(outliers_df)\n",
        "\n",
        "#################################################################################\n",
        "\n",
        "#INTERACTIVE PLOTS FOR TRIMMING###################################################\n",
        "#Just time series for faster performance\n",
        "\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.models import ColumnDataSource, HoverTool, BoxSelectTool, DataTable, TableColumn, CDSView, IndexFilter, DateFormatter, DatetimeTickFormatter, NumeralTickFormatter, CustomJS, Panel, Tabs, LinearAxis, Range1d, Paragraph, DatePicker, Div, BoxAnnotation\n",
        "from bokeh.layouts import gridplot, column, row\n",
        "from bokeh.io import output_notebook\n",
        "output_notebook()\n",
        "\n",
        "#Data\n",
        "#Column Names\n",
        "time = standard_fields[\"Time\"]\n",
        "tdseconds = \"Time Delta (seconds)\"\n",
        "temp = standard_fields[\"Temp\"]\n",
        "alt = standard_fields[\"Altitude\"]\n",
        "windspeed = standard_fields[\"Wind Speed\"]\n",
        "\n",
        "\n",
        "source = ColumnDataSource(data=dict(\n",
        "    index=df.index, \n",
        "    datetime=df[time], \n",
        "    timedelta=df[tdseconds], \n",
        "    temp=df[temp],\n",
        "    alt=df[alt],\n",
        "    windspeed=df[windspeed],\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "tempvstime = ColumnDataSource(data=dict(x=[], y=[]))\n",
        "altvstime = ColumnDataSource(data=dict(x=[], y=[]))\n",
        "windspeedvstime = ColumnDataSource(data=dict(x=[], y=[]))\n",
        "\n",
        "trimmedvalues = ColumnDataSource(data=dict(\n",
        "    index = [],\n",
        "    time = [],\n",
        "    temp = [],\n",
        "    alt = [],\n",
        "    windspeed = [],\n",
        "))\n",
        "\n",
        "sources = [tempvstime, altvstime, windspeedvstime]\n",
        "\n",
        "#Formatting\n",
        "datefmt = DateFormatter(format=\"%F %I:%M:%S %p\") #Format API reference: https://docs.bokeh.org/en/latest/docs/reference/models/widgets/tables.html?highlight=datatable#bokeh.models.DataTable\n",
        "width = 1000\n",
        "height = 300\n",
        "hovercolor = \"black\"\n",
        "barocolor = \"orange\"\n",
        "\n",
        "datetimevsindexhover = HoverTool( #API Reference: https://docs.bokeh.org/en/latest/docs/user_guide/tools.html#hovertool\n",
        "    tooltips=[\n",
        "        (\"Index\", \"$index\"),\n",
        "        (\"Date\", \"@datetime{%F %I:%M:%S %p}\"),\n",
        "        (\"Time Delta\", \"@{timedelta} seconds\")\n",
        "    ],\n",
        "\n",
        "    formatters={\n",
        "        \"@datetime\" : \"datetime\",\n",
        "        #\"@y1\" : \"numeral\"\n",
        "    },\n",
        "    #mode = \"vline\"\n",
        ")\n",
        "\n",
        "options = dict(x_axis_label = \"Row Index\", tools=[datetimevsindexhover, \"pan, wheel_zoom, xwheel_pan, ywheel_pan, box_select, box_zoom, reset\"], plot_width=700, plot_height=300)\n",
        "links = dict(width=width, height=height, x_axis_type=\"datetime\")\n",
        "#view = CDSView(source=source, filters=[IndexFilter(x)])\n",
        "sz = 5\n",
        "\n",
        "#INITIALIZING PLOTS************************************************************************************************\n",
        "\n",
        "#Datetime vs. Index\n",
        "f1 = figure(title = \"Datetime vs. Index\", y_axis_label = \"Date\", y_axis_type=\"datetime\", **options)\n",
        "f1.line(\"index\", \"datetime\", hover_color=\"red\", source=source)\n",
        "f1.circle(\"index\", \"datetime\", size=sz, hover_color=\"red\", source=source, selection_color = \"firebrick\",) #API Reference: https://docs.bokeh.org/en/latest/docs/user_guide/styling/plots.html#selected-and-unselected-glyphs\n",
        "\n",
        "\n",
        "#Time Delta vs. Index\n",
        "f2 = figure(title = \"Time Delta vs. Index\", y_axis_label=\"Time Delta (s)\", y_axis_type=\"log\", x_range=f1.x_range, **options)\n",
        "#f2.yaxis.formatter = DatetimeTickFormatter(seconds=[\"%S\"])\n",
        "f2.line(\"index\", \"timedelta\", hover_color=\"red\", source=source)\n",
        "f2.circle(\"index\", \"timedelta\", size=sz, hover_color=\"red\", source=source, selection_color = \"firebrick\")\n",
        "\n",
        "timecolumns = [\n",
        "    TableColumn(field=\"datetime\", title=\"Datetime\", formatter= datefmt), #Reference: https://stackoverflow.com/questions/40942168/how-to-create-a-bokeh-datatable-datetime-formatter\n",
        "    TableColumn(field=\"timedelta\", title=\"Change in time (seconds)\")\n",
        "]\n",
        "\n",
        "dt1 = DataTable(background = \"red\", source=source, columns=timecolumns)\n",
        "\n",
        "disclaimer_msg = Paragraph(text=\"\"\"*Time Delta values equal to zero will not be plotted*\"\"\")\n",
        "\n",
        "#TIME SERIES PLOTS*************************************************************************************************\n",
        "timegraphs = {\n",
        "    \"Altitude vs. Time\": \"#0eade1\", \n",
        "    \"Wind Speed vs. Time\": \"#500eec\", \n",
        "}\n",
        "\n",
        "hover_timeseries = HoverTool(\n",
        "    tooltips=[\n",
        "        (\"Index\", \"@index\"),\n",
        "        (\"Time\", \"@time{%F %I:%M:%S %p}\"),       \n",
        "        (\"Altitude\", \"@alt\"),\n",
        "        (\"Windspeed\", \"@windspeed\"),\n",
        "    ],\n",
        "\n",
        "    formatters={\n",
        "        \"@time\" : \"datetime\",\n",
        "    },\n",
        "    #mode = \"vline\"\n",
        ")\n",
        "\n",
        "#TIME SERIES PLOTS SEPARATE******************************************************************************\n",
        "timeylabels = [alt, windspeed]\n",
        "timeysourceskeys = [\"alt\", \"windspeed\"]\n",
        "time_series_options = dict(tools=[hover_timeseries, \"pan, wheel_zoom, box_select, tap, reset\"], plot_width=700, plot_height=300)\n",
        "p1, p2 = figure(), figure()\n",
        "timefigures = [p1, p2]\n",
        "\n",
        "for f, g, l, key in zip(timefigures, timegraphs, timeylabels, timeysourceskeys):\n",
        "    i = timefigures.index(f)\n",
        "    f = figure(title=g, x_range=timefigures[0].x_range, x_axis_label = \"Time\", y_axis_label=l, x_axis_type = \"datetime\", **time_series_options)\n",
        "    f.title.text_color = timegraphs[g]\n",
        "    f.yaxis.axis_label_text_color = timegraphs[g]\n",
        "    f.yaxis.major_label_text_color = timegraphs[g]\n",
        "    f.yaxis.axis_line_color = timegraphs[g]\n",
        "    f.xaxis.formatter=DatetimeTickFormatter(\n",
        "        hours=\"%I:%M:%S %p\",\n",
        "        minutes=\"%I:%M:%S %p\")\n",
        "    #f.background_fill_color = (204, 255, 255)\n",
        "    timefigures[i] = f\n",
        "    f.line(\"time\", key, color=timegraphs[g], hover_color=hovercolor, source=trimmedvalues)\n",
        "    f.circle(\"time\", key, color=timegraphs[g], hover_color=hovercolor, size = 2, source=trimmedvalues)\n",
        "    \n",
        "tab1 = Panel(child=column(timefigures[0:2]), title=\"Time Series Plots\")\n",
        "\n",
        "\n",
        "#RANGE INDICATOR*********************************************************************\n",
        "ranges = Paragraph(text=\"\"\"SELECTED INDICES: \"\"\")\n",
        "\n",
        "#FIELD TEST INFO FOR PLOTS****************************************************************\n",
        "fieldtestinfo = Div(text=\n",
        "f\"\"\"\n",
        "<p>FIELD TEST: <b>{fieldTestParameters[\"Field Test Label\"]}</b></p>\n",
        "<p>LOCATION: <b>{fieldTestParameters[\"Field Test Location\"]}</b></p>\n",
        "<p>DATE: <b>{fieldTestParameters[\"Field Test Date\"]}</b></p>\n",
        "<p>DEVICE: <b>{fieldTestParameters[\"Device Nickname\"]}</b></p>\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "#TODO DATE PICKER*************************************************************************\n",
        "#Filters to first entry with selected date\n",
        "\"\"\"\n",
        "start_date = df[date].min().date()\n",
        "end_date = df[date].max().date()\n",
        "\n",
        "date_picker = DatePicker(title=\"Select Date of Field Test\", value=start_date, min_date=start_date, max_date=end_date)\"\"\"\n",
        "\n",
        "#PLOT GENERATION**************************************************************************************************************************************************************\n",
        "#Reference for array performance https://github.com/bokeh/bokeh/blob/main/examples/interaction/js_callbacks/js_on_change.py\n",
        "source.selected.js_on_change(\"indices\", CustomJS(args=dict(\n",
        "    origin=source, \n",
        "    trimmedvalues=trimmedvalues,\n",
        "    ranges=ranges\n",
        "), \n",
        "code=\"\"\"\n",
        "    const inds = cb_obj.indices; //Gets unsorted if you do a shift click selection in datatable\n",
        "\n",
        "    const d1 = origin.data;\n",
        "    const d2 = trimmedvalues.data;\n",
        "\n",
        "    const cols = [\"temp\", \"alt\", \"windspeed\"];\n",
        "\n",
        "    inds.sort(function(a, b){return a - b});\n",
        "\n",
        "    //To clear for every box select\n",
        "    d2[\"time\"] = [];\n",
        "    d2[\"index\"] = [];\n",
        "\n",
        "    for (let x in cols)\n",
        "    {\n",
        "        d2[cols[x]] = []\n",
        "    }\n",
        "\n",
        "    //Generate the plots\n",
        "    for (let i = 0; i < inds.length; i++) \n",
        "    {\n",
        "        d2[\"time\"].push(d1[\"datetime\"][inds[i]]);\n",
        "        \n",
        "        d2[\"index\"].push(inds[i]);\n",
        "\n",
        "        for (let x in cols)\n",
        "        {\n",
        "            const label = cols[x]\n",
        "            d2[label].push(d1[label][inds[i]]);\n",
        "        } \n",
        "    }\n",
        "\n",
        "    //Display the range selection\n",
        "    ranges.text = \"SELECTED INDICES: \" + inds[0] + \" - \" + inds[inds.length-1]\n",
        "\n",
        "    //Refresh\n",
        "    trimmedvalues.change.emit()\n",
        "\n",
        "\"\"\"\n",
        "    )\n",
        ")\n",
        "\n",
        "#ORGANIZING PLOTS INTO TABS********************************************\n",
        "#tab1 = Panel(child=f3, title=\"Temp\")\n",
        "#Displaying the data\n",
        "layout1 = row(column(children=[f1, f2, disclaimer_msg]), column(children=[dt1, ranges]))\n",
        "layout2 = column(row(Tabs(tabs=[tab1]), fieldtestinfo), ranges)\n",
        "\n",
        "show(column(layout1, layout2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vtdK1xWiEf6"
      },
      "source": [
        "## Manually input the index range of interest (also indicated by SELECTED INDICES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "cnnGxUTmiEf7"
      },
      "outputs": [],
      "source": [
        "#@title Click play after inputting the index range {display-mode: \"form\"}\n",
        "\n",
        "start_index = 0 #@param {type: \"integer\"}\n",
        "end_index = 10486 #@param {type: \"integer\"}\n",
        "\n",
        "#############################################################################\n",
        "\n",
        "df_indices = df.index\n",
        "\n",
        "if start_index not in df_indices:\n",
        "    print(f\"Specified start index, {start_index}, is not in the index range of {df_indices.start} and {df_indices.stop}\")\n",
        "    \n",
        "elif end_index not in df_indices:\n",
        "    print(f\"Specified end index, {end_index}, is not in the index range of {df_indices.start} and {df_indices.stop}\")\n",
        "\n",
        "elif end_index < start_index:\n",
        "    print(f\"Specified END index, {end_index}, is less than the specified START index, {start_index}\")\n",
        "\n",
        "else:\n",
        "    trim_date_start = df[date][start_index].strftime(\"%A, %B %d, %Y, %I:%M:%S %p\")\n",
        "    trim_date_end = df[date][end_index].strftime(\"%A, %B %d, %Y, %I:%M:%S %p\")\n",
        "    print(f\"TRIMMING FROM INDEX {start_index} to INDEX {end_index}\")\n",
        "    print(\"-\"*50, trim_date_start, \"to\", trim_date_end,\"-\"*50, sep=\"\\n\")\n",
        "    df_trim = df.loc[start_index:end_index]\n",
        "#    print(f\"Review the data and proceed to STEP 8\")\n",
        "    display(df_trim)\n",
        "    \n",
        "    #TODO PUT INTO A FUNCTION\n",
        "    trimmedvalues2 = ColumnDataSource(data=dict(\n",
        "        index = df_trim.index,\n",
        "        time = df_trim[date],\n",
        "        alt = df_trim[alt],\n",
        "        windspeed = df_trim[windspeed],\n",
        "    ))\n",
        "\n",
        "    timeylabels = [alt, windspeed]\n",
        "    timeysourceskeys = [\"alt\", \"windspeed\"]\n",
        "    time_series_options = dict(tools=[hover_timeseries, \"pan, wheel_zoom, box_select, tap, reset\"], plot_width=700, plot_height=300)\n",
        "    p1, p2 = figure(), figure()\n",
        "    timefigures = [p1, p2]\n",
        "\n",
        "    for f, g, l, key in zip(timefigures, timegraphs, timeylabels, timeysourceskeys):\n",
        "        i = timefigures.index(f)\n",
        "        f = figure(title=g, x_range=timefigures[0].x_range, x_axis_label = \"Time\", y_axis_label=l, x_axis_type = \"datetime\", **time_series_options)\n",
        "        f.title.text_color = timegraphs[g]\n",
        "        f.yaxis.axis_label_text_color = timegraphs[g]\n",
        "        f.yaxis.major_label_text_color = timegraphs[g]\n",
        "        f.yaxis.axis_line_color = timegraphs[g]\n",
        "        f.xaxis.formatter=DatetimeTickFormatter(\n",
        "            hours=\"%I:%M:%S %p\",\n",
        "            minutes=\"%I:%M:%S %p\")\n",
        "        #f.background_fill_color = (204, 255, 255)\n",
        "        timefigures[i] = f\n",
        "        f.line(\"time\", key, color=timegraphs[g], hover_color=hovercolor, source=trimmedvalues2)\n",
        "        f.circle(\"time\", key, color=timegraphs[g], hover_color=hovercolor, size = 2, source=trimmedvalues2)\n",
        "\n",
        "    show(column(timefigures[0:2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "WH8P7AiTiEf7"
      },
      "outputs": [],
      "source": [
        "#@title Save the trimmed data as a .csv and .xlsx {display-mode: \"form\"}\n",
        "\n",
        "# Trimmed data corresponds to just the field test\n",
        "\n",
        "#Name your trimmed file\n",
        "trimmed_file_name = f\"{fieldTestLabel} - {fieldTestDate} - TRIM\"\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "#Clear/refresh the change history in case this cell is rerun to prevent redundant information being appended\n",
        "change_history = change_history[:ch_bound_1]\n",
        "change_history.append(f\"Data was trimmed from {trim_date_start} to {trim_date_end}\")\n",
        "#change_history.append(f\"Data was trimmed from indices {start_index + 2} and {end_index + 2}\") #Plus two for excel indexing\n",
        " \n",
        "#Get rid of the Time Delta column\n",
        "trimmed_file = df_trim.drop(columns=\"Time Delta\").reset_index(drop=True)\n",
        "\n",
        "#Rename the Time Delta (seconds) column to Sampling Interval\n",
        "trimmed_file.rename(columns={\"Time Delta (seconds)\": \"Sampling Interval (seconds)\"}, inplace = True)\n",
        "change_history.append(\"Time Delta (seconds) was renamed to Sampling Interval (seconds)\")\n",
        "\n",
        "#Create elapsed time column (Reference: https://chris35wills.github.io/time_elapsed_pandas/)\n",
        "time_position = trimmed_file.columns.get_loc(time)\n",
        "elapsed_time = trimmed_file.iloc[:,time_position] - trimmed_file.iloc[0,time_position]\n",
        "trimmed_file.insert(1, \"Elapsed Time (seconds)\", elapsed_time.dt.total_seconds(), allow_duplicates=True)                 \n",
        "change_history.append(\"Elapsed Time (seconds) column was added\")\n",
        "\n",
        "prologuepd = pd.Series(prologue)\n",
        "changehistory = pd.Series(change_history)\n",
        "\n",
        "df_trim_path_csv = cwd + \"/\" + trimmedDataFolderName + \"/\" + trimmed_file_name + \".csv\"\n",
        "df_trim_path_excel = cwd + \"/\" + trimmedDataFolderName + \"/\" + trimmed_file_name + \".xlsx\"\n",
        "\n",
        "try:\n",
        "    print(f\"Saving file as {trimmed_file_name}.csv\")\n",
        "    trimmed_file.to_csv(df_trim_path_csv, index=False)\n",
        "    print(f\"{trimmed_file_name}.csv was saved to {df_trim_path_csv}\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(f\"Is {trimmed_file_name}.csv currently open on your computer?\")\n",
        "\n",
        "try:\n",
        "    print(f\"\\nSaving file as {trimmed_file_name}.xlsx\")\n",
        "    with pd.ExcelWriter(df_trim_path_excel) as writer:\n",
        "        prologuepd.to_excel(writer, sheet_name=\"Kestrel Info\", index = False, header = False)\n",
        "        changehistory.to_excel(writer, sheet_name=\"Data Analysis Record\", index = False, header = False)\n",
        "        trimmed_file.to_excel(writer, sheet_name=\"Field Test Data\", index = False)\n",
        "    print(f\"{trimmed_file_name}.xlsx was saved to {df_trim_path_excel}\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(f\"Is {trimmed_file_name}.xlsx currently open on your computer?\")\n",
        "    \n",
        "ch_bound_2 = len(change_history)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hlnc7VRxiEf8"
      },
      "source": [
        "# DEFINING REFERENCE ALTITUDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Sr36oS47iEf8"
      },
      "outputs": [],
      "source": [
        "#@title Click play to use an interactive plot to identify baseline ranges {display-mode: \"form\"}\n",
        "\n",
        "#Run this cell once\n",
        "\n",
        "###############################################################################\n",
        "baseline = ColumnDataSource(data=dict(\n",
        "    index = trimmed_file.index, \n",
        "    time = trimmed_file[time], \n",
        "    alt = trimmed_file[alt]\n",
        "    )\n",
        ")\n",
        "\n",
        "altvstimehover = HoverTool( #API Reference: https://docs.bokeh.org/en/latest/docs/user_guide/tools.html#hovertool\n",
        "    tooltips=[\n",
        "        (\"Index\", \"$index\"),\n",
        "        (\"Date\", \"@time{%F %I:%M:%S %p}\"),\n",
        "        (\"Value\", \"$y\"),\n",
        "    ],\n",
        "\n",
        "    formatters={\n",
        "        \"@time\" : \"datetime\",\n",
        "        #\"@y1\" : \"numeral\"\n",
        "    },\n",
        "    #mode = \"vline\"\n",
        ")\n",
        "\n",
        "options = dict(x_axis_label = \"Time\", tools=[altvstimehover, \"pan, wheel_zoom, box_select, tap, reset\"], plot_width=700, plot_height=400)\n",
        "\n",
        "f = figure(title = \"Altitude vs. Time\", y_axis_label = alt, **options)\n",
        "f.xaxis.formatter = DatetimeTickFormatter(\n",
        "    seconds=[\"%I:%M:%S %p\"],\n",
        "    minutes=[\"%I:%M:%S %p\"],\n",
        "    hours=[\"%I:%M:%S %p\"]\n",
        ")\n",
        "f.line(\"time\", \"alt\", source=baseline, color = \"blue\")\n",
        "f.circle(\"time\", \"alt\", source=baseline, color= \"blue\", size = 2, selection_color=\"firebrick\")\n",
        "\n",
        "ranges = Paragraph(text=\"\"\"SELECTED INDICES: \"\"\")\n",
        "\n",
        "####################################################################\n",
        "#TODO\n",
        "baseline.selected.js_on_change(\"indices\", CustomJS(args=dict(ranges=ranges),\n",
        "code=\"\"\"\n",
        "    \n",
        "    const inds = cb_obj.indices; //Gets unsorted if you do a shift click selection in datatable\n",
        "    console.log(\"INDS: \" + inds)\n",
        "    //If condition necessary to optimize performance (so the code doesn't run for any accidental selections)\n",
        "        \n",
        "    //Display the range selection\n",
        "    ranges.text = \"SELECTED INDICES: \" + inds[0] + \" - \" + inds[inds.length-1]\n",
        "\n",
        "\"\"\"\n",
        "    )\n",
        ")                             \n",
        "####################################################################\n",
        "show(column(f, ranges))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PvZBRToiEf8"
      },
      "source": [
        "## Baseline the data\n",
        "- Input the index ranges corresponding to the altitude values to be used to baseline\n",
        "\n",
        "***Example 1***\n",
        "\n",
        "`baseline_ranges = 0, 40, 489, 520`\n",
        "- The altitude values from indices 0-40 and 489-520 will be used to baseline the altitude\n",
        "\n",
        "***Example 2***\n",
        "\n",
        "`baseline_ranges = 100, 250`\n",
        "- The altitude values from indices 100-250 will be used to baseline the altitude\n",
        "\n",
        "***Afterwards,*** select the desired baseline method\n",
        "- Options are \"LINEAR\", \"AVERAGE\", or \"CONSTANT\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "BXtXDkSViEf8"
      },
      "outputs": [],
      "source": [
        "#@title Click play to baseline data after specifying information {display-mode: \"form\"}\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "\n",
        "#####################################################################\n",
        "\n",
        "baseline_data_step = False\n",
        "\n",
        "#Input the index ranges here\n",
        "baseline_ranges = \"\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "#Method to get the format into [[1,2], [3,4], [5, 6], ...]\n",
        "baseline_ranges_cleaned = baseline_ranges.strip(\",\").replace(\",\", \" \").split()\n",
        "\n",
        "#Check to see if the user input an even number of ranges\n",
        "if len(baseline_ranges_cleaned) % 2 == 0:\n",
        "  for i in range(len(baseline_ranges_cleaned)):\n",
        "    baseline_ranges_cleaned[i] = int(baseline_ranges_cleaned[i])\n",
        "  baseline_ranges = []\n",
        "\n",
        "  counter = 0\n",
        "  for i in range(len(baseline_ranges_cleaned)//2):\n",
        "    baseline_ranges.append([baseline_ranges_cleaned[counter], baseline_ranges_cleaned[counter+1]])\n",
        "    counter+=2\n",
        "\n",
        "  #Uncomment the baseline method to be used\n",
        "  baseline_method = \"CONSTANT\" #@param [\"LINEAR\", \"AVERAGE\", \"CONSTANT\"]\n",
        "\n",
        "  baseline_val_constant = 0 #@param {type:\"integer\"}\n",
        "\n",
        "  ######################################################################\n",
        "  change_history = change_history[:ch_bound_2] #Refresh the change_history\n",
        "\n",
        "  def baseline(indices, data = trimmed_file, values = trimmed_file[alt], method = \"LINEAR\", baseline_val = 0.):\n",
        "      validmethods = [\"LINEAR\", \"CONSTANT\", \"AVERAGE\"]\n",
        "      method = method.upper()\n",
        "      if method in validmethods:\n",
        "\n",
        "          time_series = data[\"Elapsed Time (seconds)\"].astype(\"int\") #Elapsed Time is of type float and therefore can't be combined with a boolean operation\n",
        "          time_filter = time_series & False\n",
        "          values_series = values\n",
        "\n",
        "          for ranges in indices:\n",
        "              start = ranges[0]\n",
        "              end = ranges[1]\n",
        "              baseline_starttime = data.loc[ranges[0], time].strftime(\"%I:%M:%S %p\")\n",
        "              baseline_endtime = data.loc[ranges[1], time].strftime(\"%I:%M:%S %p\") \n",
        "              print(f\"Baselining from {baseline_starttime} at index {start} to {baseline_endtime} at index {end} using baselining method: {method}\")\n",
        "              change_history.append(f\"Data baselined from {baseline_starttime} to {baseline_endtime}\")\n",
        "              time_filter = time_filter | (time_series[start:end] | True)\n",
        "              \n",
        "          time_baseline = time_series[time_filter].values\n",
        "          \n",
        "          values_baseline = values_series[time_filter].values\n",
        "\n",
        "          time_baseline = time_baseline.reshape(len(time_baseline), 1)\n",
        "          values_baseline = values_baseline.reshape(len(values_baseline), 1)\n",
        "\n",
        "          if method == \"AVERAGE\":\n",
        "              print(f\"\\nPerforming {method} baseline procedure\")\n",
        "              baseline_avg = np.average(values_baseline)\n",
        "              print(f\"Baseline average: {baseline_avg}\")\n",
        "              baseline_array = np.full((len(time_series), 1), baseline_avg)\n",
        "              change_history.append(f\"Baseline procedure used: {method}. Baseline average: {baseline_avg}\")\n",
        "\n",
        "          elif method == \"CONSTANT\":\n",
        "              print(f\"\\nPerforming {method} baseline procedure\")\n",
        "              print(f\"Baseline constant used: {baseline_val_constant}\")\n",
        "              baseline_array = np.full((len(time_series), 1), baseline_val_constant)\n",
        "              change_history.append(f\"Baseline procedure used: {method}. Baseline constant used: {baseline_val_constant}\")\n",
        "          \n",
        "          elif method == \"LINEAR\":\n",
        "              change_history.append(f\"Baseline procedure used: {method}\")\n",
        "              print(f\"\\nPerforming {method} baseline procedure\")\n",
        "              regr = linear_model.LinearRegression()\n",
        "              regr.fit(time_baseline, values_baseline)\n",
        "              time_array = time_series.values\n",
        "              time_array = time_array.reshape(len(time_array),1)\n",
        "              baseline_array = regr.predict(time_array)\n",
        "              \n",
        "              #Slope\n",
        "              print(\"Slope =\", regr.coef_)\n",
        "              \n",
        "              #Intercept\n",
        "              print(\"Intercept =\", regr.intercept_)\n",
        "              \n",
        "              #R^2\n",
        "              r2 = regr.score(time_baseline, values_baseline)\n",
        "              print(\"R^2 =\", r2)  \n",
        "\n",
        "          print(f\"\\n{method} baseline procedure completed successfully\")\n",
        "          baseline_est = pd.Series(baseline_array[:,0], name = \"Altitude Baseline (Meters)\")\n",
        "\n",
        "\n",
        "          #Obtain the baselined values\n",
        "          values_above_baseline = values_series - baseline_est\n",
        "          values_above_baseline.rename(\"AOG (Meters)\", inplace=True)\n",
        "\n",
        "\n",
        "          return(baseline_est, values_above_baseline)\n",
        "      else:\n",
        "          print(f\"'{method}' is an invalid method for baseline estimation\")\n",
        "          print(\"Valid methods are: LINEAR, AVERAGE, CONSTANT\")\n",
        "\n",
        "  #Check for valid index range (reference: https://datascienceparichay.com/article/python-flatten-a-list-of-lists-to-a-single-list/)\n",
        "  validranges = [index for sublist in baseline_ranges for index in sublist]\n",
        "  validrange = True\n",
        "  for i in validranges:\n",
        "      if i not in trimmed_file.index:\n",
        "          validrange = False\n",
        "          \n",
        "  if validrange:\n",
        "      baseline_series, AOG_series = baseline(baseline_ranges, data = trimmed_file, values = trimmed_file[alt], method = baseline_method, baseline_val = baseline_val_constant)\n",
        "      \n",
        "      trimmed_file_baselined = trimmed_file.copy(deep=True)\n",
        "\n",
        "      #Reorder columns\n",
        "      \n",
        "      #Index location of the original altitude column\n",
        "      loc_for_aog = trimmed_file_baselined.columns.get_loc(alt)\n",
        "      \n",
        "      #Insert the Baselined altitude values\n",
        "      trimmed_file_baselined.insert(loc = loc_for_aog + 1,\n",
        "        column = baseline_series.name,\n",
        "        value = baseline_series,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "      #Insert the AOG values\n",
        "      trimmed_file_baselined.insert(loc = loc_for_aog + 2,\n",
        "        column = AOG_series.name,\n",
        "        value = AOG_series,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "  #def review_baseline():##################################################################################################\n",
        "      dot_size = 0.5    \n",
        "      \n",
        "      altvstimehover = HoverTool( #API Reference: https://docs.bokeh.org/en/latest/docs/user_guide/tools.html#hovertool\n",
        "          tooltips=[\n",
        "              (\"Index\", \"$index\"),\n",
        "              (\"Date\", \"@time{%F %I:%M:%S %p}\"),\n",
        "              (\"Altitude before baseline\", \"@alt\"),\n",
        "              (\"Altitude after baseline\", \"@aog\"),\n",
        "          ],\n",
        "\n",
        "          formatters={\n",
        "              \"@time\" : \"datetime\",\n",
        "              #\"@y1\" : \"numeral\"\n",
        "          },\n",
        "          mode = \"vline\"\n",
        "      )\n",
        "\n",
        "      source = ColumnDataSource(data=dict(\n",
        "          index = trimmed_file_baselined.index, \n",
        "          time = trimmed_file_baselined[time],\n",
        "          alt = trimmed_file_baselined[alt],\n",
        "          ab = trimmed_file_baselined[baseline_series.name],\n",
        "          aog = trimmed_file_baselined[AOG_series.name]\n",
        "          )\n",
        "      )\n",
        "\n",
        "      options = dict(x_axis_label = \"Time\", tools=[altvstimehover, \"pan, wheel_zoom, box_zoom, reset\"], plot_width=600, plot_height=400)\n",
        "      ##############################################################################\n",
        "      #Altitude Baseline Plot\n",
        "      ab = figure(title=\"Altitude Baseline (shaded areas indicate values used as baseline)\", y_axis_label = alt, **options)\n",
        "      ab.xaxis.formatter = DatetimeTickFormatter(\n",
        "          seconds=[\"%I:%M:%S %p\"],\n",
        "          minutes=[\"%I:%M:%S %p\"],\n",
        "          hours=[\"%I:%M:%S %p\"]\n",
        "      )\n",
        "      ab.line(\"time\", \"alt\", source=source, color=\"orange\", legend_label = \"Barometric Altitude\")\n",
        "      ab.circle(\"time\", \"alt\", source=source, size = dot_size, color=\"orange\")\n",
        "      \n",
        "      ab.line(\"time\", \"ab\", source=source, color=\"green\", line_width=2, legend_label = \"Baseline Altitude\")\n",
        "\n",
        "      #Highlight the selected ranges\n",
        "      for period in baseline_ranges:\n",
        "          leftbound = trimmed_file_baselined.loc[period[0], time]\n",
        "          rightbound = trimmed_file_baselined.loc[period[1], time]\n",
        "          baseline_box = BoxAnnotation(left=leftbound, right=rightbound, fill_alpha=0.2, fill_color=\"green\")\n",
        "          ab.add_layout(baseline_box)\n",
        "\n",
        "      ##############################################################################\n",
        "      #Altitude Above Ground Plot\n",
        "      aog = figure(title = \"Altitude Above Ground\", x_range = ab.x_range, y_axis_label = alt, **options)\n",
        "      aog.xaxis.formatter = DatetimeTickFormatter(\n",
        "          seconds=[\"%I:%M:%S %p\"],\n",
        "          minutes=[\"%I:%M:%S %p\"],\n",
        "          hours=[\"%I:%M:%S %p\"]\n",
        "      )\n",
        "      aog.line(\"time\", \"aog\", source=source)\n",
        "      aog.circle(\"time\", \"aog\", source=source, size = dot_size)\n",
        "\n",
        "      show(column(ab, aog))\n",
        "\n",
        "      baseline_data_step = True\n",
        "\n",
        "      display(trimmed_file_baselined)\n",
        "  ###########################################################################################################################\n",
        "  else:\n",
        "      print(f\"Specified baseline ranges,{validranges}, do not fall within {trimmed_file.index.start} and {trimmed_file.index.stop}\")\n",
        "\n",
        "elif len(baseline_ranges_cleaned) == 0:\n",
        "  print(\"Please specify two numbers for baseline_ranges\")\n",
        "\n",
        "else:\n",
        "  print(\"Please input an EVEN number of baseline ranges\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "akzH6CxniEf-"
      },
      "outputs": [],
      "source": [
        "#@title Save the preprocessed data to a .csv and .xlsx {display-mode: \"form\"}\n",
        "\n",
        "# Preprocessed data corresponds to just the field test with baselined altitude values\n",
        "\n",
        "if not baseline_data_step:\n",
        "  trimmed_file_baselined = trimmed_file.copy(deep=True)\n",
        "\n",
        "#Name your preprocessed data file\n",
        "preprocessed_data_name = f\"{fieldTestLabel} - {fieldTestDate} - {deviceNickName} - PREPROCESSED\"\n",
        "\n",
        "############################################################################### \n",
        "\n",
        "changehistory = pd.Series(change_history)\n",
        "\n",
        "preprocessed_data_path_csv = cwd + \"/\" + preprocessedDataFolderName + \"/\" + preprocessed_data_name + \".csv\"\n",
        "preprocessed_data_path_excel = cwd + \"/\" + preprocessedDataFolderName + \"/\" + preprocessed_data_name + \".xlsx\"\n",
        "\n",
        "try:\n",
        "    print(f\"Saving file as {preprocessed_data_name}.csv\")\n",
        "    trimmed_file_baselined.to_csv(preprocessed_data_path_csv, index=False)\n",
        "    print(f\"{preprocessed_data_name}.csv was saved to {preprocessed_data_path_csv}\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(f\"Is {preprocessed_data_name}.csv currently open on your computer?\")\n",
        "\n",
        "try:\n",
        "    print(f\"\\nSaving file as {preprocessed_data_name}.xlsx\")\n",
        "    with pd.ExcelWriter(preprocessed_data_path_excel) as writer:\n",
        "        prologuepd.to_excel(writer, sheet_name=\"Kestrel Info\", index = False, header = False)\n",
        "        changehistory.to_excel(writer, sheet_name=\"Data Analysis Record\", index = False, header = False)\n",
        "        trimmed_file_baselined.to_excel(writer, sheet_name=\"Field Test Data with Baseline\", index = False)\n",
        "    print(f\"{preprocessed_data_name}.xlsx was saved to {preprocessed_data_path_excel}\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(f\"Is {preprocessed_data_name}.xlsx currently open on your computer?\")\n",
        "\n",
        "generate_plots = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qtNZsFriEf-"
      },
      "source": [
        "***END OF PREPROCESSING STAGE***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uRD1L5BiEf-"
      },
      "source": [
        "# GENERATE STANDARDIZED SET OF PLOTS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to use this section\n",
        "![](https://user-images.githubusercontent.com/47094586/225396563-6b3c8a4d-18d3-45d6-946c-cf80cce289de.gif)"
      ],
      "metadata": {
        "id": "GAKaJb8iPNNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZwYMGvAiEf_"
      },
      "outputs": [],
      "source": [
        "#@title Click play to select units {display-mode: \"form\"}\n",
        "\n",
        "if not generate_plots:\n",
        "  print(\"Please first save the preprocessed data before generating plots\")\n",
        "\n",
        "else:\n",
        "\n",
        "  df_pp = trimmed_file_baselined.copy(deep=True)\n",
        "  filter = df_pp.copy(deep=True)\n",
        "\n",
        "  def initialize_plots(filter=df_pp):\n",
        "\n",
        "    #Choosing the unit from the \n",
        "    for field, unit in zip(supported_units, unit_select):\n",
        "        supported_units[field] = plot_units[unit.value]\n",
        "        \n",
        "    for field in supported_units:\n",
        "        columns[field] = supported_units[field]\n",
        "        \n",
        "    #Data\n",
        "    source = {\"index\": filter.index,}\n",
        "\n",
        "    for key in selected_units:\n",
        "        source[key] = filter[columns[key]].copy(deep=True)\n",
        "        \n",
        "    source = ColumnDataSource(data=source)\n",
        "\n",
        "    tooltips = [(\"Index\", \"$index\"), (\"Time\", \"@Time{%F %I:%M:%S %p}\")]\n",
        "    \n",
        "    for field in source.data.keys():\n",
        "        if field != \"Time\" and field != \"index\":\n",
        "          field_adjusted = \"{\" + field + \"}\"\n",
        "          tooltips.append((field, f\"@{field_adjusted}\"))\n",
        "\n",
        "    hover = HoverTool(\n",
        "        tooltips=tooltips,\n",
        "\n",
        "        formatters={\n",
        "            \"@Time\" : \"datetime\",\n",
        "        },\n",
        "        #mode = \"vline\"\n",
        "    )\n",
        "\n",
        "    return source, hover\n",
        "\n",
        "  def kt_to_bft(knots):\n",
        "      \n",
        "  #Using this chart as a reference https://www.weather.gov/mfl/beaufort\n",
        "\n",
        "      Bft = []\n",
        "      \n",
        "      for knots in knots:\n",
        "          if (0 <= knots < 1):\n",
        "              Bft.append(0)\n",
        "          elif (1 <= knots < 3):\n",
        "              Bft.append(1)\n",
        "          elif (3 <= knots < 6):\n",
        "              Bft.append(2)\n",
        "          elif (6 <= knots < 10):\n",
        "              Bft.append(3)\n",
        "          elif (10 <= knots < 16):\n",
        "              Bft.append(4)\n",
        "          elif (16 <= knots < 21):\n",
        "              Bft.append(5)\n",
        "          elif (21 <= knots < 27):\n",
        "              Bft.append(6)\n",
        "          elif (27 <= knots < 33):\n",
        "              Bft.append(7)\n",
        "          elif (33 <= knots < 40):\n",
        "              Bft.append(8)\n",
        "          elif (40 <= knots < 47):\n",
        "              Bft.append(9)\n",
        "          elif (47 <= knots < 55):\n",
        "              Bft.append(10)\n",
        "          elif (55 <= knots < 63):\n",
        "              Bft.append(11)\n",
        "          elif (63 <= knots < 71): #Could also do 64 <= knots...; I wonder how high the Kestrel can measure the WS in knots\n",
        "              Bft.append(12)\n",
        "              \n",
        "      return Bft\n",
        "\n",
        "  #df_pp naming convention comes from dataframe_preprocessed\n",
        "\n",
        "  #Temperature\n",
        "  if selected_units[\"Temp\"] == \"Celsius\":\n",
        "      temp_f = ((9/5) * df_pp[temp]) + 32\n",
        "      df_pp.insert(loc = df_pp.columns.get_loc(temp) + 1,\n",
        "        column = \"Temp (Fahrenheit)\",\n",
        "        value = temp_f,\n",
        "        allow_duplicates=True)\n",
        "  elif selected_units[\"Temp\"] == \"Fahrenheit\":\n",
        "      temp_c = (df_pp[temp] - 32) * (5/9)\n",
        "      df_pp.insert(loc = df_pp.columns.get_loc(temp) + 1,\n",
        "        column = \"Temp (Celsius)\",\n",
        "        value = temp_c,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      \n",
        "  #AOG\n",
        "  if selected_units[\"Altitude\"] == \"Meters\": #Can refer to it using the raw altitude name since AOG will be in the same units\n",
        "      \n",
        "      #Meters to Feet\n",
        "      ft = df_pp[AOG_series.name] * 3.2808\n",
        "      df_pp.insert(loc = df_pp.columns.get_loc(AOG_series.name) + 1,\n",
        "        column = \"AOG (Feet)\",\n",
        "        value = ft,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "  elif selected_units[\"Altitude\"] == \"Feet\":\n",
        "      \n",
        "      #Feet to Meters\n",
        "      meters = df_pp[AOG_series.name] / 3.2808    \n",
        "      df_pp.insert(loc = df_pp.columns.get_loc(AOG_series.name) + 1,\n",
        "        column = \"AOG (Meters)\",\n",
        "        value = meters,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "  #Wind Speed\n",
        "  loc_for_ws = df_pp.columns.get_loc(windspeed)\n",
        "\n",
        "  if selected_units[\"Wind Speed\"] == \"m/s\":\n",
        "      \n",
        "      # m/s to ft/s\n",
        "      ft_per_s = df_pp[windspeed] * 3.2808\n",
        "      df_pp.insert(loc = loc_for_ws + 1,\n",
        "        column = \"Wind Speed (ft/s)\",\n",
        "        value = ft_per_s,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # m/s to mph\n",
        "      mph = df_pp[windspeed] * 2.2369\n",
        "      df_pp.insert(loc = loc_for_ws + 2,\n",
        "        column = \"Wind Speed (mph)\",\n",
        "        value = mph,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # m/s to kt\n",
        "      kt = df_pp[windspeed] * 1.9438\n",
        "      df_pp.insert(loc = loc_for_ws + 3,\n",
        "        column = \"Wind Speed (kt)\",\n",
        "        value = kt,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "      # kt to Bft\n",
        "      Bft = kt_to_bft(kt)\n",
        "      df_pp.insert(loc = loc_for_ws + 4,\n",
        "        column = \"Wind Speed (Bft)\",\n",
        "        value = Bft,\n",
        "        allow_duplicates=True)    \n",
        "\n",
        "  elif selected_units[\"Wind Speed\"] == \"ft/s\":\n",
        "      \n",
        "      # ft/s to m/s\n",
        "      m_per_s = df_pp[windspeed] / 3.2808\n",
        "      df_pp.insert(loc = loc_for_ws + 1,\n",
        "        column = \"Wind Speed (m/s)\",\n",
        "        value = m_per_s,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # mph\n",
        "      mph = m_per_s * 2.2369\n",
        "      df_pp.insert(loc = loc_for_ws + 2,\n",
        "        column = \"Wind Speed (mph)\",\n",
        "        value = mph,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # kt\n",
        "      kt = m_per_s * 1.9438\n",
        "      df_pp.insert(loc = loc_for_ws + 3,\n",
        "        column = \"Wind Speed (kt)\",\n",
        "        value = kt,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "      # Bft\n",
        "      Bft = kt_to_bft(kt)\n",
        "      df_pp.insert(loc = loc_for_ws + 4,\n",
        "        column = \"Wind Speed (Bft)\",\n",
        "        value = Bft,\n",
        "        allow_duplicates=True)        \n",
        "      \n",
        "  elif selected_units[\"Wind Speed\"] == \"mph\":\n",
        "      \n",
        "      # mph to m/s\n",
        "      m_per_s = df_pp[windspeed] / 2.2369\n",
        "      df_pp.insert(loc = loc_for_ws + 1,\n",
        "        column = \"Wind Speed (m/s)\",\n",
        "        value = ft_per_s,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # ft/s\n",
        "      ft_per_s = m_per_s * 3.2808\n",
        "      df_pp.insert(loc = loc_for_ws + 2,\n",
        "        column = \"Wind Speed (ft/s)\",\n",
        "        value = mph,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # kt\n",
        "      kt = m_per_s * 1.9438\n",
        "      df_pp.insert(loc = loc_for_ws + 3,\n",
        "        column = \"Wind Speed (kt)\",\n",
        "        value = kt,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "      # kt to Bft\n",
        "      Bft = kt_to_bft(kt)\n",
        "      df_pp.insert(loc = loc_for_ws + 4,\n",
        "        column = \"Wind Speed (Bft)\",\n",
        "        value = Bft,\n",
        "        allow_duplicates=True)      \n",
        "      \n",
        "  elif selected_units[\"Wind Speed\"] == \"kt\":\n",
        "      \n",
        "      # kt to m/s\n",
        "      m_per_s = df_pp[windspeed] / 1.9438\n",
        "      df_pp.insert(loc = loc_for_ws + 1,\n",
        "        column = \"Wind Speed (m/s)\",\n",
        "        value = ft_per_s,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # ft/s\n",
        "      ft_per_s = m_per_s * 3.2808\n",
        "      df_pp.insert(loc = loc_for_ws + 2,\n",
        "        column = \"Wind Speed (ft/s)\",\n",
        "        value = mph,\n",
        "        allow_duplicates=True)\n",
        "      \n",
        "      # mph\n",
        "      mph = m_per_s * 2.2369\n",
        "      df_pp.insert(loc = loc_for_ws + 3,\n",
        "        column = \"Wind Speed (mph)\",\n",
        "        value = kt,\n",
        "        allow_duplicates=True)    \n",
        "      \n",
        "      # kt to Bft\n",
        "      Bft = kt_to_bft(df_pp[windspeed])\n",
        "      df_pp.insert(loc = loc_for_ws + 4,\n",
        "        column = \"Wind Speed (Bft)\",\n",
        "        value = Bft,\n",
        "        allow_duplicates=True)     \n",
        "\n",
        "  #Not sure if converting FROM Bft is really necessary    \n",
        "  #elif selected_units[\"Wind Speed\"] == \"Bft\":\n",
        "\n",
        "  import bokeh.palettes as palettes\n",
        "  #https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20Layout.html#natural-sizes-and-arrangements-using-hbox-and-vbox\n",
        "\n",
        "  selected_units_no_time = selected_units.copy()\n",
        "  selected_units_no_time.pop(\"Time\")\n",
        "  colors_length = len(selected_units_no_time)\n",
        "\n",
        "  if colors_length <= 8:\n",
        "    colors = palettes.Colorblind[colors_length] #Colorblind palette has a maximum of 8 colors, which should be enough https://docs.bokeh.org/en/latest/docs/reference/palettes.html#d3-palettes\n",
        "  \n",
        "  else:\n",
        "    colors = palettes.Category20[colors_length]\n",
        "\n",
        "  #Unit selection\n",
        "  temp_units = [\"Celsius\", \"Fahrenheit\"]\n",
        "  alt_units = [\"Meters\", \"Feet\"]\n",
        "  ws_units = [\"Meters per second\", \"Feet per second\", \"Miles per hour\", \"Knots\", \"Beaufort\"]\n",
        "\n",
        "  supported_units = {\n",
        "      \"Temp\": temp_units,\n",
        "      \"Altitude\": alt_units,\n",
        "      \"Wind Speed\": ws_units,\n",
        "  }\n",
        "\n",
        "  unit_select = []\n",
        "  for field in supported_units:\n",
        "      unit_select.append(widgets.ToggleButtons(\n",
        "          options=[i for i in supported_units[field]],\n",
        "          description=field,\n",
        "          disabled=False,\n",
        "          button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "          #tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
        "      #    icons=['check'] * 3\n",
        "      )\n",
        "      )\n",
        "\n",
        "  #Color selection\n",
        "  color_selections = {\n",
        "      \"Altitude\": f\"#0eade1\",\n",
        "      \"Temp\": f\"#e01b9a\",\n",
        "      \"Wind Speed\": f\"#500eec\",\n",
        "      \"Mag. Dir.\": f\"#08a108\",\n",
        "      \"Rel. Hum.\": f\"#12cab4\"\n",
        "      }\n",
        "  for unit, color in zip(selected_units_no_time, colors):\n",
        "    if unit in color_selections:\n",
        "      color_selections[unit] = widgets.ColorPicker(\n",
        "                              concise=False,\n",
        "                              description=unit,\n",
        "                              value=color_selections[unit],\n",
        "                              disabled=False\n",
        "    )\n",
        "    else:\n",
        "      color_selections[unit] = widgets.ColorPicker(\n",
        "                              concise=False,\n",
        "                              description=unit,\n",
        "                              value=color,\n",
        "                              disabled=False\n",
        "    )      \n",
        "\n",
        "  items_layout = Layout(width='auto')     # override the default width of the button to 'auto' to let the button grow\n",
        "\n",
        "  unit_layout = Layout(display='flex',\n",
        "                      flex_flow='row', \n",
        "                      align_items='stretch', \n",
        "                      #border='solid',\n",
        "                      width='100%')\n",
        "\n",
        "  colors_layout = Layout(display='flex',\n",
        "                      flex_flow='column', \n",
        "                      align_items='stretch', \n",
        "                      #border='solid',\n",
        "                      width='100%')\n",
        "\n",
        "  box = Box(children=unit_select, layout=unit_layout)\n",
        "\n",
        "  box2 = Box(children=[color_selections[unit] for unit in color_selections], layout=colors_layout)\n",
        "\n",
        "  #children = [box, box2] includes the color selection\n",
        "  children = [box]\n",
        "  tab = widgets.Tab()\n",
        "  tab.children = children\n",
        "  tab.titles = [\"Units\"]\n",
        "\n",
        "  customize_plots = True\n",
        "\n",
        "  display(tab)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1KGPOo3iEf_"
      },
      "source": [
        "## Time Series Separate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "Mk2AKK5kiEf_"
      },
      "outputs": [],
      "source": [
        "#@title Click play to generate time series plots {display-mode: \"form\"}\n",
        "#from bokeh.models import ColorPicker\n",
        "\n",
        "if not customize_plots:\n",
        "  print(customize_plots_message)\n",
        "\n",
        "else:\n",
        "  from bokeh.io import output_file\n",
        "  from bokeh.models import Select\n",
        "\n",
        "  time_series_separate_path = f\"TIME SERIES SEPARATE - {fieldTestLabel} - {fieldTestDate}.html\"\n",
        "\n",
        "  output_file(f\"{plotsFolderName}/{time_series_separate_path}\")\n",
        "\n",
        "  #Formatting\n",
        "  datefmt = DateFormatter(format=\"%F %I:%M:%S %p\") #Format API reference: https://docs.bokeh.org/en/latest/docs/reference/models/widgets/tables.html?highlight=datatable#bokeh.models.DataTable\n",
        "  width = 900\n",
        "  height = 300\n",
        "\n",
        "  #view = CDSView(source=source, filters=[IndexFilter(x)])\n",
        "  hovercolor = \"black\"\n",
        "  sz = 3\n",
        "\n",
        "  #FIELD TEST INFO FOR PLOTS****************************************************************\n",
        "  fieldtestinfo = Div(text=\n",
        "  f\"\"\"\n",
        "  <p>FIELD TEST: <b>{fieldTestParameters[\"Field Test Label\"]}</b></p>\n",
        "  <p>LOCATION: <b>{fieldTestParameters[\"Field Test Location\"]}</b></p>\n",
        "  <p>DATE: <b>{fieldTestParameters[\"Field Test Date\"]}</b></p>\n",
        "  <p>DEVICE: <b>{fieldTestParameters[\"Device Nickname\"]}</b></p>\n",
        "  \"\"\"\n",
        "  )\n",
        "\n",
        "  #TIME SERIES PLOTS*************************************************************************************************\n",
        "  source, hover = initialize_plots(filter)\n",
        "\n",
        "  \"\"\"Unit selection in the plots\n",
        "  unit_selections = {\n",
        "      \"Temp\": Select(title = \"Units\", value = \"Celsius\", options = temp_units),\n",
        "      \"Altitude\": Select(title = \"Units\", value = \"Meters\", options = alt_units),\n",
        "      \"Wind Speed\": Select(title = \"Units\", value = \"Meters per second\", options = ws_units)\n",
        "  }\n",
        "  \"\"\"\n",
        "\n",
        "  #TIME SERIES PLOTS SEPARATE******************************************************************************\n",
        "  time_series_options = dict(tools=[hover, \"pan, wheel_zoom, box_select, tap, reset\"], plot_width=width, plot_height=height)\n",
        "  timefigures = []\n",
        "  #color_pickers = [] #For changing the colors in the plot; disabling for now to optimize performance\n",
        "  line_color = []\n",
        "  circle_color = []\n",
        "  plot_layout = []\n",
        "\n",
        "  for title in selected_units_no_time:\n",
        "      \n",
        "      color = color_selections[title].value\n",
        "      \n",
        "\n",
        "      if title == \"Mag. Dir.\":\n",
        "          timefigures.append(figure(title=f\"{columns[title]} vs. Time\", y_range=(-40, 400), x_axis_label = \"Time\", y_axis_label=columns[title], x_axis_type = \"datetime\", **time_series_options))\n",
        "      else:\n",
        "          timefigures.append(figure(title=f\"{columns[title]} vs. Time\", x_axis_label = \"Time\", y_axis_label=columns[title], x_axis_type = \"datetime\", **time_series_options))\n",
        "          line_color.append(timefigures[-1].line(\"Time\", title, color=color, hover_color=hovercolor, source=source))\n",
        "      timefigures[-1].title.text_color = color\n",
        "  #         timefigures[-1].yaxis.axis_label_text_color = color\n",
        "  #         timefigures[-1].yaxis.major_label_text_color = color\n",
        "  #         timefigures[-1].yaxis.axis_line_color = color\n",
        "      timefigures[-1].xaxis.formatter=DatetimeTickFormatter(\n",
        "          hours=\"%I:%M:%S %p\",\n",
        "          minutes=\"%I:%M:%S %p\")\n",
        "      timefigures[-1].x_range = timefigures[0].x_range\n",
        "      circle_color.append(timefigures[-1].circle(\"Time\", title, color=color, size=sz, hover_color=hovercolor, source=source))\n",
        "\n",
        "  #     #Changing the colors of the plot lines\n",
        "  #     color_pickers.append(ColorPicker(title=f\"{title} Color\"))\n",
        "  #     color_pickers[-1].js_link(\"color\", line_color[-1].glyph, \"line_color\")\n",
        "  #     color_pickers[-1].js_link(\"color\", circle_color[-1].glyph, \"line_color\")\n",
        "  #     color_pickers[-1].js_link(\"color\", circle_color[-1].glyph, \"fill_color\")\n",
        "  #     color_pickers[-1].js_link(\"color\", circle_color[-1].glyph, \"fill_color\")     \n",
        "\n",
        "  #     #Changing the colors of the plot title, axes\n",
        "  #     color_pickers[-1].js_link(\"color\", timefigures[-1].title, \"text_color\")          \n",
        "\n",
        "  # #         color_pickers[-1].js_link(\"color\", timefigures[-1].yaxis, \"axis_label_text_color\")        \n",
        "  # #         color_pickers[-1].js_link(\"color\", timefigures[-1].yaxis, \"major_label_text_color\")        \n",
        "  # #         color_pickers[-1].js_link(\"color\", timefigures[-1].yaxis, \"axis_line_color\")       \n",
        "\n",
        "  #     color_pickers[-1].color = color\n",
        "\n",
        "      #plot_layout.append(row(timefigures[-1], color_pickers[-1]))\n",
        "\n",
        "      plot_layout.append(row(timefigures[-1]))\n",
        "\n",
        "  tab1 = Panel(child=column(fieldtestinfo, column(plot_layout)), title=\"Time Series Plots\")\n",
        "\n",
        "  layout1 = Tabs(tabs=[tab1])\n",
        "\n",
        "  show(column(layout1))\n",
        "\n",
        "  print(f\"\\n This plot was saved to {plotsFolderName} as {time_series_separate_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaMymk2MiEgA"
      },
      "source": [
        "## Time Series Superimposed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNweG9vSiEgA"
      },
      "outputs": [],
      "source": [
        "#@title Click play to choose the variables to view on one time series plot {display-mode: \"form\"}\n",
        "\n",
        "if not customize_plots:\n",
        "  print(customize_plots_message)\n",
        "\n",
        "else:\n",
        "  variable_1 = widgets.ToggleButtons(\n",
        "      options=[field for field in selected_units_no_time],\n",
        "      description='Variable 1',\n",
        "      disabled=False,\n",
        "      button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "      tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
        "  #     icons=['check'] * 3\n",
        "  )\n",
        "\n",
        "  variable_2 = widgets.ToggleButtons(\n",
        "      options=[field for field in selected_units_no_time],\n",
        "      description='Variable 2',\n",
        "      disabled=False,\n",
        "      button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "      tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
        "  #     icons=['check'] * 3\n",
        "  )\n",
        "\n",
        "  superimposed_variables = [variable_1, variable_2]\n",
        "  box_superimposed = Box(children=superimposed_variables, layout=unit_layout)\n",
        "\n",
        "  time_series_superimposed_step = True\n",
        "\n",
        "  display(box_superimposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X11asTobiEgA"
      },
      "outputs": [],
      "source": [
        "#@title Click play to generate the superimposed Time Series plot {display-mode: \"form\"}\n",
        "\n",
        "if not time_series_superimposed_step:\n",
        "  print(\"Please FIRST run the ABOVE cell to select the variables to view on a time series plot\")\n",
        "\n",
        "else:\n",
        "  from bokeh.io import output_file\n",
        "\n",
        "  time_series_superimposed_path = f\"{variable_1.value} VS. {variable_2.value} - TIME SERIES - {fieldTestLabel} - {fieldTestDate}.html\"\n",
        "\n",
        "  output_file(f\"{plotsFolderName}/{time_series_superimposed_path}\")\n",
        "\n",
        "  #TIME SERIES PLOTS SUPERIMPOSED***************************************************************************************************************************************\n",
        "\n",
        "  source, hover = initialize_plots(filter)\n",
        "\n",
        "  var1 = variable_1.value\n",
        "  var2 = variable_2.value\n",
        "\n",
        "  var1_label = columns[var1]\n",
        "  var2_label = columns[var2]\n",
        "\n",
        "  var1_min = filter[var1_label].min()\n",
        "  var1_max = filter[var1_label].max()\n",
        "\n",
        "  var2_min = filter[var2_label].min()\n",
        "  var2_max = filter[var2_label].max()\n",
        "\n",
        "  var1_color = color_selections[var1].value\n",
        "  var2_color = color_selections[var2].value\n",
        "\n",
        "  width_superimposed = 1500\n",
        "  height_superimposed = 500\n",
        "  glyph_size = 5\n",
        "\n",
        "  superimposed1_options = dict(tools=[hover, \"pan, wheel_zoom, box_select, tap, reset\"], plot_width=width_superimposed, plot_height=height_superimposed)\n",
        "\n",
        "  superimposed1 = figure(y_range = (var1_min, var1_max), x_axis_label = \"Time\", y_axis_label = var1_label,\n",
        "                        x_axis_type=\"datetime\", **superimposed1_options)\n",
        "  superimposed1.xaxis.formatter=DatetimeTickFormatter(\n",
        "      hours=\"%I:%M:%S %p\",\n",
        "      minutes=\"%I:%M:%S %p\"\n",
        "  )\n",
        "\n",
        "  superimposed1.yaxis.axis_label_text_color = var1_color\n",
        "  superimposed1.yaxis.major_label_text_color = var1_color\n",
        "  superimposed1.yaxis.axis_line_color = var1_color\n",
        "\n",
        "  if var1 != \"Mag. Dir.\":\n",
        "    superimposed1.line(\"Time\", var1, color=var1_color, hover_color=\"red\", source=source, legend_label = var1_label)\n",
        "  if var1 in glyphs:\n",
        "    superimposed1.scatter(\"Time\", var1, marker = glyphs[var1], size = glyph_size, color=var1_color, hover_color=\"red\", source=source, legend_label = var1_label)\n",
        "  else:\n",
        "    superimposed1.scatter(\"Time\", var1, size = glyph_size, color=var1_color, hover_color=\"red\", source=source, legend_label = var1_label)\n",
        "\n",
        "  superimposed1.extra_y_ranges[\"var2\"] = Range1d(start=var2_min, end=var2_max)\n",
        "\n",
        "  if var2 != \"Mag. Dir.\":\n",
        "    superimposed1.line(\"Time\", var2, color=var2_color, hover_color=\"red\", source=source, legend_label = var2_label, y_range_name =\"var2\")\n",
        "  \n",
        "  if var2 in glyphs:\n",
        "    superimposed1.scatter(\"Time\", var2, marker = glyphs[var2], size = glyph_size, color=var2_color, hover_color=\"red\", source=source, legend_label = var2_label, y_range_name = \"var2\")\n",
        "  else:\n",
        "    superimposed1.scatter(\"Time\", var2, size = glyph_size, color=var2_color, hover_color=\"red\", source=source, legend_label = var2_label, y_range_name = \"var2\")\n",
        "\n",
        "  ax2 = LinearAxis(y_range_name=\"var2\", axis_label = var2_label, \n",
        "                  major_label_text_color = color_selections[var2].value, \n",
        "                  axis_label_text_color = color_selections[var2].value, \n",
        "                  axis_line_color= color_selections[var2].value)\n",
        "\n",
        "  superimposed1.add_layout(ax2, \"right\") \n",
        "\n",
        "  superimposed1.legend.click_policy= \"hide\"\n",
        "\n",
        "  tab2 = Panel(child=column(fieldtestinfo, superimposed1), title=\"Time Series Superimposed\")\n",
        "\n",
        "  layout2 = Tabs(tabs=[tab2])\n",
        "\n",
        "  show(layout2)\n",
        "\n",
        "  print(f\"\\nThis plot was saved to {plotsFolderName} as {time_series_superimposed_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6gxp9-WiEgB"
      },
      "source": [
        "## Altitude Profiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V0fSocqiEgB"
      },
      "outputs": [],
      "source": [
        "#@title Click play to generate a series of altitude profiles {display-mode: \"form\"}\n",
        "\n",
        "if not customize_plots:\n",
        "  print(customize_plots_message)\n",
        "\n",
        "else:\n",
        "  from bokeh.io import output_file\n",
        "\n",
        "  alt_profiles_separate_path = f\"ALTITUDE PROFILES SEPARATE - {fieldTestLabel} - {fieldTestDate}.html\"\n",
        "\n",
        "  output_file(f\"{plotsFolderName}/{alt_profiles_separate_path}\")\n",
        "\n",
        "  #ALTITUDE PROFILES*********************************************************\n",
        "  \n",
        "  source, hover = initialize_plots(filter)\n",
        "  glyph_size = 5\n",
        "\n",
        "  #######################################################################\n",
        "\n",
        "\n",
        "  alt_profiles_options = dict(tools=[hover, \"pan, wheel_zoom, box_select, tap, reset\"], plot_width=700, plot_height=300)\n",
        "  altprofiles = [alt for alt in selected_units_no_time if alt != \"Altitude\"]\n",
        "  altprofiles_plots = []\n",
        "\n",
        "  for title in altprofiles:\n",
        "      alt_plot_color = color_selections[title].value\n",
        "      label = columns[title]\n",
        "      if title == \"Mag. Dir.\":\n",
        "          altprofiles_plots.append(figure(title=label, x_axis_label = columns[\"Altitude\"], y_range=(-40, 400), y_axis_label=label, **alt_profiles_options))\n",
        "      else:\n",
        "          altprofiles_plots.append(figure(title=label, x_axis_label = columns[\"Altitude\"], y_axis_label=label, **alt_profiles_options))\n",
        "      if title in glyphs:\n",
        "        altprofiles_plots[-1].scatter(\"Altitude\", title, marker = glyphs[title], size = glyph_size, color=alt_plot_color, hover_color=hovercolor, source=source)\n",
        "      else:\n",
        "        altprofiles_plots[-1].scatter(\"Altitude\", title, size = glyph_size, color=alt_plot_color, hover_color=hovercolor, source=source)\n",
        "      \n",
        "      altprofiles_plots[-1].title.text_color = alt_plot_color\n",
        "      altprofiles_plots[-1].yaxis.axis_label_text_color = alt_plot_color\n",
        "      altprofiles_plots[-1].yaxis.major_label_text_color = alt_plot_color\n",
        "      altprofiles_plots[-1].yaxis.axis_line_color = alt_plot_color\n",
        "      \n",
        "      altprofiles_plots[-1].x_range = altprofiles_plots[0].x_range\n",
        "      \n",
        "  tab3 = Panel(child=column(fieldtestinfo, column(altprofiles_plots)), title=\"Altitude Profiles\")\n",
        "\n",
        "  layout3 = Tabs(tabs=[tab3])\n",
        "\n",
        "  show(layout3)\n",
        "\n",
        "  print(f\"\\nThis plot was saved to {plotsFolderName} as {alt_profiles_separate_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eti73AD7iEgB"
      },
      "source": [
        "## Altitude Profiles Superimposed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1I_y6naiEgB"
      },
      "outputs": [],
      "source": [
        "#@title Click play to choose the variables to view on a single altitude plot {display-mode: \"form\"}\n",
        "\n",
        "if not customize_plots:\n",
        "  print(customize_plots_message)\n",
        "\n",
        "else:\n",
        "  alt_profile_superimposed_step = False\n",
        "\n",
        "  altprofiles = [alt for alt in selected_units_no_time if alt != \"Altitude\"]\n",
        "  alt_variable_1 = widgets.ToggleButtons(\n",
        "      options=[field for field in altprofiles],\n",
        "      description='Variable 1',\n",
        "      disabled=False,\n",
        "      button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "      tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
        "  #     icons=['check'] * 3\n",
        "  )\n",
        "\n",
        "  alt_variable_2 = widgets.ToggleButtons(\n",
        "      options=[field for field in altprofiles],\n",
        "      description='Variable 2',\n",
        "      disabled=False,\n",
        "      button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "      tooltips=['Description of slow', 'Description of regular', 'Description of fast'],\n",
        "  #     icons=['check'] * 3\n",
        "  )\n",
        "\n",
        "  alt_superimposed_variables = [alt_variable_1, alt_variable_2]\n",
        "  box_alt_superimposed = Box(children=alt_superimposed_variables, layout=unit_layout)\n",
        "\n",
        "  alt_profile_superimposed_step = True\n",
        "\n",
        "  display(box_alt_superimposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85ZW46fpiEgB"
      },
      "outputs": [],
      "source": [
        "#@title Click play to generate the superimposed altitude profile plot {display-mode: \"form\"}\n",
        "\n",
        "if not alt_profile_superimposed_step:\n",
        "  print(\"Please FIRST run the ABOVE cell to select the variables to view on the altitude plot\")\n",
        "\n",
        "else:\n",
        "  from bokeh.io import output_file\n",
        "\n",
        "  alt_profile_superimposed_path = f\"{alt_variable_1.value} VS. {alt_variable_2.value} - ALTITUDE PROFILE - {fieldTestLabel} - {fieldTestDate}.html\"\n",
        "\n",
        "  output_file(f\"{plotsFolderName}/{alt_profile_superimposed_path}\")\n",
        "\n",
        "  #ALTITUDE PROFILES SUPERIMPOSED***************************************************************************************************************************************\n",
        "  \n",
        "  source, hover = initialize_plots(filter)\n",
        "\n",
        "  #######################################################################\n",
        "\n",
        "  var1 = alt_variable_1.value\n",
        "  var2 = alt_variable_2.value\n",
        "\n",
        "  var1_label = columns[var1]\n",
        "  var2_label = columns[var2]\n",
        "\n",
        "  var1_min = filter[var1_label].min()\n",
        "  var1_max = filter[var1_label].max()\n",
        "\n",
        "  var2_min = filter[var2_label].min()\n",
        "  var2_max = filter[var2_label].max()\n",
        "\n",
        "  var1_color = color_selections[var1].value\n",
        "  var2_color = color_selections[var2].value\n",
        "\n",
        "  width_superimposed = 1000\n",
        "  height_superimposed = 500\n",
        "  glyph_size = 5\n",
        "\n",
        "  altsuperimposed_options = dict(tools=[hover, \"pan, wheel_zoom, box_select, reset\"], plot_width=width_superimposed, plot_height=height_superimposed)\n",
        "\n",
        "  altsuperimposed = figure(y_range = (var1_min, var1_max), x_axis_label=columns[\"Altitude\"], y_axis_label=var1_label, **altsuperimposed_options)\n",
        "\n",
        "  altsuperimposed.yaxis.axis_label_text_color = var1_color\n",
        "  altsuperimposed.yaxis.major_label_text_color = var1_color\n",
        "  altsuperimposed.yaxis.axis_line_color = var1_color\n",
        "\n",
        "  if var1 in glyphs:\n",
        "    altsuperimposed.scatter(\"Altitude\", var1, marker = glyphs[var1], color=var1_color, size = glyph_size, hover_color=\"red\", source=source, legend_label = var1_label)\n",
        "  else:\n",
        "    altsuperimposed.scatter(\"Altitude\", var1, color=var1_color, size = glyph_size, hover_color=\"red\", source=source, legend_label = var1_label)\n",
        "\n",
        "  altsuperimposed.extra_y_ranges[\"var2\"] = Range1d(start=var2_min, end=var2_max)\n",
        "\n",
        "  if var2 in glyphs:\n",
        "    altsuperimposed.scatter(\"Altitude\", var2, marker = glyphs[var2], color=var2_color, size = glyph_size, hover_color=\"red\", source=source, legend_label = var2_label, y_range_name = \"var2\")\n",
        "  else:\n",
        "    altsuperimposed.scatter(\"Altitude\", var2, color=var2_color, size = glyph_size, hover_color=\"red\", source=source, legend_label = var2_label, y_range_name = \"var2\")    \n",
        "\n",
        "  ax2 = LinearAxis(y_range_name=\"var2\", axis_label = var2_label, \n",
        "                  major_label_text_color = color_selections[var2].value, \n",
        "                  axis_label_text_color = color_selections[var2].value, \n",
        "                  axis_line_color= color_selections[var2].value)\n",
        "\n",
        "  altsuperimposed.add_layout(ax2, \"right\") \n",
        "\n",
        "  altsuperimposed.legend.click_policy= \"hide\"\n",
        "\n",
        "  tab4 = Panel(child=column(fieldtestinfo, altsuperimposed), title=\"Altitude Profiles Superimposed\")\n",
        "\n",
        "  layout4 = Tabs(tabs=[tab4])\n",
        "\n",
        "  show(layout4)\n",
        "\n",
        "  print(f\"\\nThis plot was saved to {plotsFolderName} as {alt_profile_superimposed_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xL25xutiEgC"
      },
      "source": [
        "## A.R.T.S Plot (**A**lt. vs. **R**el hum, **T**emp, wind **S**peed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYJik4a4iEgC"
      },
      "outputs": [],
      "source": [
        "#@title Click play to generate the plot {display-mode: \"form\"}\n",
        "\n",
        "if not customize_plots:\n",
        "  print(customize_plots_message)\n",
        "\n",
        "else:\n",
        "  from bokeh.io import output_file\n",
        "\n",
        "  geoff_plot_path = f\"A.R.T.S Plot - {fieldTestLabel} - {fieldTestDate}.html\"\n",
        "\n",
        "  output_file(f\"{plotsFolderName}/{geoff_plot_path}\")\n",
        "\n",
        "  source, hover = initialize_plots()\n",
        "\n",
        "  #The Geoff Exclusive********************************************************************************\n",
        "  glyph_size = 5\n",
        "  geoffsourcekeys = [\"Temp\", \"Wind Speed\", \"Rel. Hum.\"]\n",
        "  geoff_options = dict(tools=[hover, \"pan, wheel_zoom, box_select, reset\"], plot_width=1000, plot_height=500)\n",
        "  geoffcolors = [\"#e01b9a\", \"#500eec\", \"#08d4c6\"]\n",
        "  geoffp = figure(y_axis_label = columns[\"Altitude\"], **geoff_options)\n",
        "\n",
        "  for key, c in zip(geoffsourcekeys, geoffcolors):\n",
        "      geoffp.scatter(key, \"Altitude\", marker = glyphs[key], size = glyph_size, color=c, hover_color=hovercolor, source=source, legend_label=columns[key])\n",
        "  geoffp.legend.click_policy=\"hide\"\n",
        "\n",
        "  tab5 = Panel(child=column(fieldtestinfo, geoffp), title=\"A.R.T.S Plot\")\n",
        "\n",
        "  layout5 = Tabs(tabs=[tab5])\n",
        "\n",
        "  show(layout5)\n",
        "\n",
        "  print(f\"\\n This plot was saved to {plotsFolderName} as {geoff_plot_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "au23zBgFiEft",
        "s1oZeUJhiEf3",
        "Hlnc7VRxiEf8",
        "3uRD1L5BiEf-",
        "w1KGPOo3iEf_",
        "AaMymk2MiEgA",
        "i6gxp9-WiEgB",
        "Eti73AD7iEgB",
        "8xL25xutiEgC"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}